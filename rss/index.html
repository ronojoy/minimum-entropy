<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Minimum entropy]]></title><description><![CDATA[science |  computation | inference]]></description><link>http://my-ghost-blog.com/</link><generator>Ghost v0.4.1</generator><lastBuildDate>Sat, 29 Mar 2014 20:18:01 GMT</lastBuildDate><atom:link href="http://my-ghost-blog.com/rss/" rel="self" type="application/rss+xml"/><author><![CDATA[Ronojoy Adhikari]]></author><ttl>60</ttl><item><title><![CDATA[Adieu, Matlab]]></title><description><![CDATA[<p>This post is about how I said goodbye to Matlab and replaced it with open source tools built using the Python programming language. </p>

<h2 id="matlabthegoodbadandugly">Matlab : the good, bad and ugly</h2>

<p>Matlab is a great environment for the beginner because of its interactive interpreter and excellent plotting features. These let the beginner focus on the task at hand, which may be to experiment with a numerical algorithm or to plot data, rather than worry about compilers, libraries, and the Unix shell. Matlab provides a nice array-oriented syntax that avoids loops and allows for very succint code. The integrated development environment, with a debugger and a profiler, allows hassle-free programming. The large number of toolboxes, both commercial and those contributed by the user community, cover large areas of science and engineering. If Matlab's native m-code is not fast enough for the needs at hand, C or Java functions can be called from the Matlab interpreter. </p>

<p>While these features undoubtedly contribute to Matlab's popularity, a more experienced programmer will soon feel constrained by Matlab's drawbacks. For me, these are</p>

<ul>
<li><p><strong>A poor programming language</strong> : the Matlab (MATrix LABoratory) language was designed to work with vectors and matrices and, unsurprisingly, is rather bad at handling other data types. Features like object orientation are an afterthought and, so, do not sit at all well with the rest of the language. </p></li>
<li><p><strong>No web deployable interface</strong> : 2013 marked the year when more people accessed the internet through mobile devices than through laptops or desktops. Scientific computing must now be made available as a service, where the client can use a mobile device to access a high-performance computing platform, submit a computational task and receive the results, including visualizations, on the same device. Currently, Matlab offers now way of being deployable on the web as a service. Its Java GUI and muPAD notebook
are 1990s technology struggling to keep up with the demands of 21st century computing. </p></li>
<li><p><strong>Poor support for multi-core and multi-thread computing</strong> : On that same vein, Matlab was built in the era of the single core processor. Performance was driven by increasing clock speeds and FLOPS mattered the most. Today, clock speeds have saturated, multi-core and multi-thread is the norm, and performance tends to be limited by memory access and not FLOPS. We will need to radically redesign numerical algorithms to leverage the change in hardware. I doubt Matlab to be the platform around which we will see these changes. The support that Matlab has for multi-core and multi-thread numerics comes from expensive add-on toolboxes which are priced per core. The cost of deployment turns out to be a good fraction of the hardware cost. I find this pricing model unacceptable. </p></li>
<li><p><strong>Closed source and expensive</strong> : the internals of Matlab and many of the toolboxes are closed source. This is a real obstacle to open, reproducible science. It also presents a barrier to the large-scale adoption of scientific computing at the undergraduate level in countries with small per-capita educational budgets.   </p></li>
</ul>

<p>A lot of experienced programmers absolutely love to hate Matlab. Here is a whole blog <a href='http://abandonmatlab.wordpress.com/' >devoted to exposing Matlab warts and getting people to abandon it</a>. "It is not good for you" it warns!</p>

<p>What is good for you, though, is a modern, object-oriented programming language that is open source, free of cost, allows code sharing and integrates well with the web. For me, the computing ecosystem built around the Python programming language is the most attractive of such options. </p>

<h2 id="pythonnumpyscipyandfriends">Python, Numpy, Scipy and friends</h2>

<p>To describe Python, let me quote Guido von Rossum's executive summary of the language he created: </p>

<blockquote>
  <p>Python is an interpreted, object-oriented, high-level programming language with dynamic semantics. Its high-level built in data structures, combined with dynamic typing and dynamic binding, make it very attractive for Rapid Application Development, as well as for use as a scripting or glue language to connect existing components together. Python's simple, easy to learn syntax emphasizes readability and therefore reduces the cost of program maintenance. Python supports modules and packages, which encourages program modularity and code reuse. The Python interpreter and the extensive standard library are available in source or binary form without charge for all major platforms, and can be freely distributed. </p>
  
  <p>Often, programmers fall in love with Python because of the increased productivity it provides. Since there is no compilation step, the edit-test-debug cycle is incredibly fast. Debugging Python programs is easy: a bug or bad input will never cause a segmentation fault. Instead, when the interpreter discovers an error, it raises an exception. When the program doesn't catch the exception, the interpreter prints a stack trace. A source level debugger allows inspection of local and global variables, evaluation of arbitrary expressions, setting breakpoints, stepping through the code a line at a time, and so on. The debugger is written in Python itself, testifying to Python's introspective power. On the other hand, often the quickest way to debug a program is to add a few print statements to the source: the fast edit-test-debug cycle makes this simple approach very effective. </p>
</blockquote>

<p>The high-level built in data structures in Python do not include vectors and matrices, the very ones that are needed for numerical computing and are the basic data types in Matlab. This gap has been filled by <a href='http://numpy.scipy.org/' >Numpy</a> which brings to Python the ndarray data type and universal functions, ufuncs, that accept and return ndarrays. Quoting the <a href='http://en.wikipedia.org/wiki/NumPy' >Wikipedia entry on Numpy</a> :</p>

<blockquote>
  <p>NumPy is an extension to the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.</p>
</blockquote>

<p>Put Python and Numpy together and you have the basic tools for building scientific libraries. <a href='http://www.scipy.org/' >Scipy</a> is a collection of such libraries :  </p>

<blockquote>
  <p>SciPy contains modules for optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing, ODE solvers and other tasks common in science and engineering.</p>
</blockquote>

<p>Scipy provides most of the functionality of Matlab. The analogue of Matlab toolboxes are scikits, packages that extend the functionality of scipy. In addition, there is a large collection of  software contributed by a vibrant community. </p>

<h2 id="bundles">Bundles</h2>

<h2 id="ides">IDEs</h2>

<ul>
<li><strong>Spyder</strong></li>
<li><strong>IEP</strong></li>
</ul>

<h2 id="visualization">Visualization</h2>

<ul>
<li><strong>Matplotlib</strong> </li>
<li><strong>ggplot</strong></li>
<li><strong>matplotlib for D3</strong></li>
<li><strong>Mayavi</strong></li>
</ul>

<h2 id="dataanalysis">Data analysis</h2>

<ul>
<li><strong>Pandas</strong></li>
<li><strong>scikits-learn</strong></li>
<li><strong>pytables</strong></li>
</ul>

<h2 id="interfacingtotheweb">Interfacing to the web</h2>

<p>Ipython is an enhanced interpreter for Python that lets you be more productive. The Ipython Notebook interface is just awesome ! </p>

<h2 id="matropolisthemovie">Matropolis : the movie</h2>

<p>After that long post it is time for something less heavy, nay, positively light: geek humour! <a href='https://www.youtube.com/user/jamiealexandre' >Jamie Alexandre</a> makes creative reuse of Fritz Lang's Metropolis to tell the story of Matlab and Python. It is 15 minutes long, but patience pays, as Guido van Rossum makes an appearence in the last minute. Enjoy!</p>

<iframe width="480" height="360" src='http://www.youtube.com/embed/1lBeungEnx4'  frameborder="0" allowfullscreen></iframe>]]></description><link>http://my-ghost-blog.com/adieu-matlab/</link><guid isPermaLink="false">5566acab-26ae-4d2c-ba6d-045b0e849522</guid><dc:creator><![CDATA[Ronojoy Adhikari]]></dc:creator><pubDate>Sat, 22 Mar 2014 11:16:45 GMT</pubDate></item><item><title><![CDATA[The trace of grace]]></title><description><![CDATA[<p>An undergraduate student at Cornell University has downloaded the complete result of the ICSE and CBSE exams for the year 2013. The result, hosted on  <a href='http://www.cisce.ndtv.com/' >http://www.cisce.ndtv.com/</a> , could be downloaded in its entirety because the data was stored in a manner that is easily revealed by studying the source code of the web page. This exploit, if it can be so called, raises concerns about privacy of information, the impropriety of a private news channel hosting the results of a nationwide public exam, and most seriously, the allegation of marks tampering.</p>

<p>Having access to scorecards of all the candidates who appeared in the examination Debarghya Das, the Cornell student, computed the histogram of the exam scores for each subject and  noticed an anomaly : some scores would never occur in the histograms. Specifically, the scores 36, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 56, 57, 59, 61, 63, 65, 67, 68, 70, 71, 73, 75, 77, 79, 81, 82, 84, 85, 87, 89, 91, and 93 were never obtained by any of the candidates in any of the subjects! A histogram with such holes would already be highly improbable for any one subject, but what takes it to the realms of impossibility is that such histograms appear for all subjects! Here is the histogram, taken from Debarghya Das’s blog.</p>

<p><img src='http://my-ghost-blog.com/content/images/2014/Mar/histogramwithholes.png'  alt="histogramswithholes" /></p>

<p>What is the probability that such histograms can be obtained  by chance ? Intuitively, it appears to be very low, but it is quite easy to make a quantitative estimate by assuming the simplest form for the probability of the score distribution, namely that each score is equally likely. In Bayesian terms this would mean an uniform prior on the scores, equal to 1/100. Assuming that the candidates are all identical (in terms of preparation, ability and so on) and independent (they do not copy from each other and so on)  the probability that N_j candidates get a score of j can be taken to be (fittingly for what appears to be a fishy matter) Poisson distributed</p>

<pre><code>\[ P(N_j) = \frac{\mu_j^{N_j} e^{-\mu_j}}{N_j !} \]
</code></pre>

<p>where \mu<em>j = \langle N</em>j \rangle is the expected number of candidates with score j.  For an exam with 100, 000 candidates the expected number in each bin is 1000. We now want the probability that there is a “hole” in the histogram, that is, there are no candidates with a score of j. This probability is</p>

<pre><code>\[ \mbox{Prob(No candidates scored j}) = P(N_j = 0) = e^{-\mu_j} = e^{-1000} \approx 0 \]
</code></pre>

<p>The probability that there will be a hole in any one of the subject histograms is approximately 1 in 10 followed by a 1000 zeros, infinitesimally small. It is then entirely improbable that there will be holes at identical places for all the subject histograms. This can only point to some unspecified form of “data manipulation”. Finally, below is an example of a histogram from a nation wide multiple choice exam, taken by approximately 10,000 candidates. The candidates mark their answers on a machine-readable sheet and the final scores are generated without human intervention. Notice the complete absence of holes away from the tails of the histogram. <br />
noholes</p>

<p>Histogram obtained in a national exam, taken by approximately 10,000 candidates, where scores are generated without human intervention.</p>

<p><img src='http://my-ghost-blog.com/content/images/2014/Mar/histogramwithoutholes.png'  alt="histogramswithoutholes" /></p>

<p>[Edit on  09.06. 13 : The Learning Point website has much more data on odd looking histograms from the board exams. Thanks to Seema Singh for this. ]</p>]]></description><link>http://my-ghost-blog.com/the-trace-of-grace-marks/</link><guid isPermaLink="false">57ec4d67-f9dd-40dc-b2c9-e7b4aa31ad99</guid><dc:creator><![CDATA[Ronojoy Adhikari]]></dc:creator><pubDate>Sat, 22 Mar 2014 08:06:03 GMT</pubDate></item><item><title><![CDATA[The Indus script]]></title><description><![CDATA[<p>The Indus script is the name given to a system of signs, yet to be deciphered, used by the peoples of the Indus valley civilization (IVC). For the uninitiated reader, the IVC was contemporaneous to other major civilizations of the Bronze age like Egypt and Mesopotamia, but covered an area which was much larger. It was, in fact, the largest civilization of the Bronze Age. The civilization grew from the peoples who had first domesticated wheat around Mehrgarh in Baluchistan, and rice around Lahuradeva in Uttar Pradesh, flourished over a 2000 year period, but underwent a precipitous decline around 1900 BCE. </p>

<p><a href="">Kavita Gangal</a> and I did a spatio-temporal analysis of the growth and decay of the civilization. We compiled a database of Indus cites, grouped them by their size and the times during which they were inhabited, and plotted the result as a function of time, starting from the earliest times around 7000BCE and ending at 1000BCE. This animation is the key result.</p>

<iframe width="420" height="315" src='http://www.youtube.com/embed/zpYTGHLZHPU'  frameborder="0" allowfullscreen></iframe>

<p>I have more to say about this in a later post, but for now, let us return to the Indus script. </p>

<p>During the mature period of the IVC spanning 2500 BCE – 1900 BCE, the Indus script was widely used, with standardization across the entire geographical area of the civilization. The main purpose of the script was to facilitate trade and it must have had other uses too. Though it was discovered almost a century ago, the script remains undeciphered. The reasons for this include the brevity of the writing, the uncertainty over what language or languages the IVC peoples spoke, and the absence of any bilingual stellae like the Rosetta Stone. Given the variety of writing systems that are in use today  and have been known in the past, what can we say about the nature of the writing system that is the Indus script ?</p>

<p>A sensible way to go about looking for an answer is to cast the question as one of Bayesian inference. We frame a set of hypotheses, call them H1, H2 ..Hn and collect all the data, call that D, and then use Bayes theorem to compute the posterior probability of the hypotheses being true,  in the light of the data D. These probabilities would, of course, change if new data was made available to augment D. If we assumed a logically exhaustive and mutually exclusive list of hypotheses, then P(H1 | D) + P(H2 | D)  … P(Hn | D) = 1, so that, any increase in the probability of one of the hypothesis would automatically decrease the probability of the remaining hypotheses. The Bayesian procedure, being inductive, gives the probability of any of the hypotheses being true, but does not provide the deductive certainty that Boolean logic does. Bayesian inference is, then, a formalisation of the process of rational thought that we use in everyday life, as <a href='http://horadecubitus.wordpress.com/' >Rahul Siddharthnan</a> and I <a href='http://www.thehindu.com/sci-tech/science/article2747042.ece' >described elsewhere</a>.</p>

<p>What sort of hypotheses should we make about the Indus script as a writing system ? Starting without bias, we could assume that it could be any one of the known writing systems or that it is an unknown writing system. If the number of known writing systems is N, say, we have N + 1 hypothesis to start with. Confronting these hypotheses with the data, which would be the sum total of our knowledge of all these writing systems and of the Indus script, we could obtain the probability that the Indus script belongs to one of the known writing systems or that it is an unknown writing system.</p>

<p>This task, being fairly enormous, we could start with something simpler and focus not on the sum total of our knowledge of writing systems, but perhaps only a few features of known writing systems. One aspect amenable to quantitative study has to do with the frequencies with which signs appear in the writing system, that is their statistical properties. Then, a more limited form of inference would be to compute the statistical properties of the different writing systems, compare them to the computed statistical properties of the Indus script and then use Bayes theorem to  obtain the probability that the Indus script is any one of them, or, is an unknown writing system.</p>

<p>This was the reasoning behind a series of papers in Science, PNAS, and  PLoS One  that I co-authored with Iravatham Mahadevan,  Rajesh Rao  and and others on using statistical signatures to uncover that nature of the Indus script as a writing system. While we never explicitly formalised this Bayesian argument in our papers, it was always implicit in the way we understood, interpreted, and presented the results of our statistical analysis. Our conclusion was that, based on statistical signatures, there is more evidence that the Indus script functions like one of the known linguistic writing systems, than some unknown writing system. A detailed explanation of our method has now appeared as a comment in  Computational Linguistics.</p>

<p>The results we obtained can be bettered by using more data on known writing systems, sharper statistical measures, and formalising the Bayesian inferential procedure. Epigraphists, archaelogists and historians all argue, using data from their respective fields, in favour of the Indus script being a known writing system. Our work, based on statistical analysis, adds to this body of evidence.</p>]]></description><link>http://my-ghost-blog.com/the-indus-script/</link><guid isPermaLink="false">b70b8349-2a3f-443e-997c-479f680914b8</guid><dc:creator><![CDATA[Ronojoy Adhikari]]></dc:creator><pubDate>Sat, 22 Mar 2014 07:56:25 GMT</pubDate></item><item><title><![CDATA[The power in the law of culturomic fame]]></title><description><![CDATA[<p>Magazines like Forbes regularly publish a list of the rich. What would it take to publish a similar list of the famous ? To draw the list we would need to rank the famous and thus need a measure of fame. Two researchers now claim to have to invented a measure of what they call culturomic fame. </p>

<p>In short, instead of using citations (which reflects the influence of a scientist on their peer group) Bohanon and Veres query the Google n-gram database for the appearance of an author’s name. This, presumably, reflects the influence of the scientist on larger society. The arbitrarily chosen unit of fame is the number of times Charles Darwin’s name appears in the database starting from the year he was 30 till the year 2000 and, unsurprisingly, is called the Darwin. A scientist with f Darwin of (so-called) culturomic fame has f times the citation of Darwin. Computing f for scientists listed on Wikipedia results in this Hall of Fame.</p>

<p>Perhaps the most interesting statistical feature in the distribution is that fame distribution is highly skewed. This has been noted by Steven Pinker who suspects that fame is power-law distributed. Is fame, like wealth, then Pareto-distributed ?</p>

<p><img src='http://my-ghost-blog.com/content/images/2014/Mar/fameexponent1.png'  alt="culturomic fame graph" /></p>

<p>To get to the bottom of this, I downloaded this data and studied the empirical distribution. It appeared reasonable to assume a power-law form and so I take it as given that fame follows a Pareto distribution. (In Bayesian terms, the prior on the Pareto distribution is 1, and I only do parameter estimation, not model selection). The minimum value of fame in the dataset is fmin = 0.020009526 milliDarwin and I used this as the cutoff in the Pareto distribution. I used a Jeffreys prior for the exponent and then calculated its Bayesian posterior distribution. The exponent is gamma distributed and its mean is an optimum point estimate. I estimated the exponent to be 0.19713. This means that fame is distributed as P(f) ~ 1/f^(1 + 0.19713). Since the Pareto exponent is less than 1, the expected value of fame is infinite. </p>

<p>So, while one cannot expect to become arbitrarily rich (resources are bounded) it appears that one may expect to become arbitrarily famous! Who said that the rich were like the famous ? </p>]]></description><link>http://my-ghost-blog.com/the-power-in-the-law-of-culturomic-fame/</link><guid isPermaLink="false">d80438e5-4b04-400c-85e5-83ba9046be80</guid><dc:creator><![CDATA[Ronojoy Adhikari]]></dc:creator><pubDate>Fri, 21 Mar 2014 19:36:49 GMT</pubDate></item><item><title><![CDATA[Cooking ? DAG that!]]></title><description><![CDATA[<p>Cooking is, at a fundamental level, like doing a chemistry or physics experiment. This is contention is likely to raise the eyebrows of our traditional khansama or modern sous chef , but let me explain. The aim of cooking is to start with certain raw materials, combine them in the right proportion, add energy to the combination in the form of heat, and coax them into reacting in just the way that finally produces a delightful sensation to the palate and nourishment for the body. What is different, really, and what makes cooking more of an art than a science, is that we are still at a stage where the details of the reactions that take place between the ingredients is not well understood. Compared with a well-studied reaction in organic chemisty,  where we understand the mechanism almost down to the last electron transfer, we are still in the stone age when it comes to culinary reactions. The nascent field of molecular gastronomy, however, is trying to move cooking from an empirical art to a rational science. The late <a href='http://en.wikipedia.org/wiki/Nicholas_Kurti' >Nicholas Kurti</a>, an Oxford professor of physics and pioneer in this field, had his own television show called the Physicist in the Kitchen. Kurti is supposed to have made the challenging remark</p>

<blockquote>
  <p>"I think it is a sad reflection on our civilization that while we can and do measure the temperature in the atmosphere of Venus we do not know what goes on inside our soufflés.“</p>
</blockquote>

<p>Inspired by this infusion of the scientific method into cooking, why not change the traditional format of a recipie from copious paragraphs to a flow chart ? Here is my attempt at presenting a fish curry recipe in terms of a flow chart. Enjoy!</p>

<p><img src='http://my-ghost-blog.com/content/images/2014/Mar/fishcurrydag.png'  alt="fishcurrydag.png" /></p>]]></description><link>http://my-ghost-blog.com/cooking-dag-that/</link><guid isPermaLink="false">695b5e6f-6ba2-4583-b809-9328f6f3044e</guid><dc:creator><![CDATA[Ronojoy Adhikari]]></dc:creator><pubDate>Fri, 21 Mar 2014 19:34:43 GMT</pubDate></item><item><title><![CDATA[Google n-grams and Ravi Shankar]]></title><description><![CDATA[<p><img src='http://my-ghost-blog.com/content/images/2014/Mar/sitarsarodngram.png'  alt="sitar sarod n-grams" /></p>

<p>Here is a bit of musicology using Google N-grams. The graph shows the occurrence of the terms sitar and sarod in the N-gram collection in the last two centuries. First, this goes to show that the sitar has always been by far the more popular instrument and, even at present, is probably at least twice as popular as the sarod. Second, there is jump in the sitar frequency in the mid 1960s. This jump correlates rather well with a similar jump in Ravi Shankar around the same time. Two other well-known sitarists’ names are not so correlated. The tentative conclusion ? Ravi Shankar may have been responsible for the rise in popularity of the sitar in the West. Yes, we know that for a fact, but this is a good example of the kind of use N-grams might could be put to in musicology. Of course, the leap from correlation to causation is fraught with danger, but there are now well-defined ways to infer causation. With careful use, I am sure Google N-grams is going to throw up more interesting insights into human activity. </p>]]></description><link>http://my-ghost-blog.com/musicology-with-google-n-grams/</link><guid isPermaLink="false">b52b5923-5b73-4450-9479-b2014182a8a4</guid><dc:creator><![CDATA[Ronojoy Adhikari]]></dc:creator><pubDate>Fri, 21 Mar 2014 19:34:30 GMT</pubDate></item></channel></rss>